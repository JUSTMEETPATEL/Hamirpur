import ollama

response = ollama.list()
image_dir = 'data_dir/mobile_phone.jpg'

# Load the image
with open(image_dir, 'rb') as file:
    image_data = file.read()

# Function to generate questions and interact based on user responses
def categorize_e_waste(image_data):
    # Initial prompt to the model to generate simple, actionable questions
    response = ollama.chat(
        model='james:latest',  # You can use the model you're working with here
        messages=[
            {
                "role": "system",
                "content": "You are an expert in waste categorization based on images. Your task is to ask simple, actionable "
                           "questions that help classify items into 'Reduce', 'Reuse', or 'Recycle'. Focus on the item's "
                           "condition, whether it can be reused, and the materials it is made from. Avoid asking about "
                           "complex concepts like environmental impact or sustainability."
            },
            {
                "role": "user",
                "content": "Analyze this image and generate simple questions that will help classify the mobile phone "
                           "into one of the categories: 'Reduce', 'Reuse', or 'Recycle'. Ask about its condition, "
                           "whether it can still be used, and if it can be repurposed or recycled. Keep the questions "
                           "easy for the user to answer.",
                "images": [image_data]
            }
        ]
    )

    # Get the list of questions generated by the model
    generated_questions = response['message']['content']
    # print("Generated Questions:\n", generated_questions)

    # Clean the response to extract only the questions, removing any intro text
    questions_start_index = generated_questions.find("1.")  # Find where the first question starts
    cleaned_questions = generated_questions[questions_start_index:].strip()  # Extract everything from the first question onwards

    # Split the cleaned questions into a list (assuming they are separated by '\n')
    questions = [q.strip() for q in cleaned_questions.split('\n') if q.strip()]

    # List to store user answers
    answers = []

    # Ask each question one by one and collect answers
    for idx, question in enumerate(questions, 1):
        print(f"{question}")
        answer = input("Answer: ")
        answers.append(answer.lower())  # Append the user's answer to the list

    # After all answers are collected, send them to the model for analysis
    follow_up = ollama.chat(
        model='llama3.2:latest',
        messages=[
            {
                "role": "system",
                "content": "You are now analyzing the user's responses to classify the e-waste item. Based on the "
                           "answers, suggest the next step for categorizing the item."
            },
            {
                "role": "user",
                "content": f"User's responses: {answers}. Analyze this and decide whether to categorize the item as"
                           f" Reduce, Reuse, or Recycle."
            }
        ]
    )

    # Analyze the model's decision based on the answers provided
    classification_response = follow_up['message']['content']
    print("\nModel's Analysis \n", classification_response)

    # Final categorization
    final_decision = ollama.chat(
        model='llama3.2:latest',
        messages=[
            {
                "role": "system",
                "content": "You are classifying the e-waste item based on the user's answers. Provide the final "
                           "categorization (Reduce, Reuse, or Recycle)."
            },
            {
                "role": "user",
                "content": f"Based on the user's answers: {answers}, provide the final categorization "
                           f"(Reduce, Reuse, or Recycle)."
            }
        ]
    )

    print("\nFinal Decision:\n", final_decision['message']['content'])

# Call the function
categorize_e_waste(image_data)
